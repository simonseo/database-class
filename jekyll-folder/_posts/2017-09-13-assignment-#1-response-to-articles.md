---
layout: post
title: "Assignment #1"
description: Response to recent news articles related to database or big data
---

**[How to find out what people really think](https://www.economist.com/news/books-and-arts/21722612-data-mining-becoming-more-and-more-precise-how-find-out-what-people-really-think])**

This article explains what big data is, how it is different from data of the past, and from that difference reflects on the past US presidential election. Traditionally in the social sciences, surveys of several thousand respondents at most are widely used. In contrast, there are “four unique powers of Big Data” that the article points out:

1. it provides new sources of information, such as pornographic searches
1. it captures what people actually do or think, rather than what they choose to tell pollsters
1. it enables researchers to home in on and compare demographic or geographic subsets
1. it allows for speedy randomized controlled trials that demonstrate not just correlation but causality.

From these differences, the author points out that the reason Hilary Clinton’s data analysts failed to capture the sentiments of some regions is because they relied too much on results from traditional methods of data collection such as polls and surveys, which do not necessarily depict one’s opinions accurately. All in all, big data has become a prominent tool to precisely analyze a population or even individuals.

**[Math Isn't Biased, But Big Data Is.](https://www.forbes.com/sites/metabrown/2017/08/30/math-isnt-biased-but-big-data-is/#8ce119f4d564)**

A point that the last article points out is that data can cause inequality, not because the math and the method is wrong, but because the people and data collection and analysis can be biased. This article puts it this way: "Math doesn’t cause bias, and Big Data is only partly to blame. The biggest source of bias in data analysis is and always will be people, both technical and business people, failing to admit that bias exists, failing to look for it, and failing to do anything constructive about it." If previously collected data is biased, then analysis arising from that data may well be biased as well. For example, a tech company recently hosted an object recognition program on their webpage but it constantly misclassified black people to be gorillas; the reason being that the program was not trained enough on black people. If the same system had its dataset consist of only black people and gorillas, it would differentiate the two almost perfectly while failing to classify white people. That is one reason why data collection and analysis must be conducted by a diverse range of people, whether it be gender, religion, race, social status, or culture.

**[A rare look inside LAPD's use of data](http://money.cnn.com/2017/09/11/technology/future/lapd-big-data-palantir/index.html)**

To briefly summarize the content of the article, "surveillance today is unprecedented" and "sharing data helps cops do their jobs" using novel data sharing and data analysis techniques but not without problems. "Citizens without police contact can be tracked" for being related to a felonious person in any way. This is problematic for victims of social bias and sometimes analysis of big data can become a self-fulfilling prophecy by pointing towards innocent yet suspicious individuals and as a result having them get in trouble with the police. Also, "not all officers love the new surveillance tools" because it not only applies to the targets of scrutiny but also to the officers, like tracking the location of the police cars every few seconds.

The data that Los Angeles Police Department uses are drawn from security camera footages, license plate photos, traffic tickets, work of fellow officers, etc. Palantir Technologies, a Silicon Valley company.

The biggest problem I believe is that big data provides the government with a massive power to control the mass excessively. At the moment no specific cases have been reported that big data messed up, but overly tracking citizens and even the police makes it uncomfortable with the smallest mistakes that one can commit.

As the article puts it, "laws haven't kept up with technology — What kind of future do we want?" A policed society that watches everyone preemptively? Or a society that limits the use of big data to solve cases, not preventing them?

